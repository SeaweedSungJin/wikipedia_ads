base_path: /dataset/evqa
image_path: datasets/real_images/Downside_Abbey.jpg
kb_json_name: encyclopedic_kb_wiki.json
text_query: Who built the choir at this abbey?
k_value: 20
m_value: 10
alpha: 0.9
search_expand: 20 # lisf of 같은거 처리용, 이미지 과샘플링
image_device: 0
# Device placement
bge_device: 1
nli_device: 2
nli_batch_size: 512
# Dedicated device for VLM to avoid sharing memory with reranker
vlm_device: 3
dataset_csv: /dataset/evqa/test.csv
id2name_paths: 
  - /dataset/inaturalist/train_id2name.json
  - /dataset/inaturalist/val_id2name.json
  - /dataset/inaturalist/test_id2name.json
  - /dataset/inaturalist/public_test_id2name.json
dataset_image_root: /dataset/inaturalist
dataset_google_root: /dataset/landmarks

dataset_start: 0
dataset_end: 5750
#dataset_start: 0
#dataset_end: 4750

text_encoder_model: facebook/contriever
segment_level: section # "section", "paragraph" or "sentence"
chunk_size: 1024
#bge_model: BAAI/bge-reranker-v2-m3
bge_model: BAAI/bge-reranker-large
bge_max_length: 1024 # ✅ 추가
bge_conf_threshold: 0.3
electra_model: cross-encoder/ms-marco-electra-base
mpnet_model: sentence-transformers/all-mpnet-base-v2 #bi-encoder

# -------------------------------
# Reranker/Image Fusion (section ranking)
# -------------------------------
# Combined per-section score = rank_img_weight * softmax(img_score) + rank_rerank_weight * sigmoid(rerank_score/temperature)
rank_img_weight: 0.7
rank_rerank_weight: 0.3
rank_text_temp: 2.0   # sigmoid temperature for text reranker scores
# rank_img_softmax_temp: 1.0  # optional softmax temperature for image doc scores

deberta_nli_model: tasksource/deberta-base-long-nli
roberta_nli_model: FacebookAI/roberta-large-mnli
deberta_v3_nli_model: microsoft/deberta-large-mnli
#nli_model: MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli
nli_max_length: 512 #long 모델 쓸때 1024
nli_max_cluster: 3
nli_e_min: 0.10 #Entailment가 이거보다 낮음 탈락 
nli_margin: 0.10 #ent-con 점수가 이거보다 낮으면 탈락 #0.0 #기존 0.1
nli_tau: 0.10 #α * 내포 - β * 모순 점수가 이거보다 낮음 탈락, 지금αβ는 둘다 1
nli_lambda: 0.7 
## Consistency selection parameters
# C_ij = max(0, alpha*Pe - beta*Pc)
nli_alpha: 1.0
nli_beta: 1.0
# 'consistency' enables greedy pruning; 'clique' uses maximal-clique method
nli_selection: consistency
# Hybrid cluster scoring (consistency mode):
# final_cluster_score = nli_hybrid_lambda * normalized_global_consistency + (1 - nli_hybrid_lambda) * mean(normalized_section_scores)
nli_hybrid_lambda: 1

# NLI model selection
nli_models:
  deberta: false
  roberta: true
  deberta_v3: false

# Reranker settings
rerankers:
  contriever: false
  jina_tiny: true
  jina_turbo: false
  bge: false
  electra: false
  mpnet: false
  q-former: false

#양방향 실험용
  nli_edge_rule: avg #both_dir or avg
  nli_dir_margin: 0.0 #0.0이면 무시됨
